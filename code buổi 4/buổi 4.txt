Lọc tuổi :
from pyspark.sql import SparkSession
from pyspark.sql.functions import col

# Khởi tạo SparkSession
spark = SparkSession.builder.appName("SparkUtilitiesDemo").getOrCreate()

# Tạo DataFrame mẫu từ dữ liệu có sẵn trong Spark
df = spark.createDataFrame([(1, "John", 25), (2, "Jane", 30), (3, "Alice", 35)],
                           ["id", "name", "age"])

# Sử dụng các Spark Utilities để xử lý DataFrame
# Ví dụ: In schema của DataFrame
df.printSchema()

# Ví dụ: Lọc các dòng có age lớn hơn 30
filtered_df = df.filter(col("age") > 30)
filtered_df.show()

# Đóng SparkSession
spark.stop()

Tinh Tong scala :
val data = Seq(1, 2, 3, 4, 5) 
val rdd = spark.sparkContext.parallelize(data) 
val sum = rdd.reduce(_ + _) 
println(sum)

Tính tổng từ 1 Đến 100: 
from pyspark import SparkContext, SparkConf

# Khởi tạo SparkContext
conf = SparkConf().setAppName("SparkUtilitiesDemo")
sc = SparkContext(conf=conf)

# Tạo một RDD chứa dữ liệu mặc định trong Spark
data = sc.parallelize(range(1, 10))

# Sử dụng spark utilities để tính tổng các số trong RDD
sum_of_numbers = data.reduce(lambda x, y: x + y)

# In kết quả
print("Tổng các số trong RDD là:", sum_of_numbers)

# Đóng SparkContext
sc.stop()